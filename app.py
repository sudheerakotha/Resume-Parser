import streamlit as st

import re

import pdfplumber

from docx import Document

import spacy



# Load the English NLP model

# Ensure you have downloaded the model: python -m spacy download en_core_web_sm

nlp = spacy.load("en_core_web_sm")



# Function to extract text from PDF

def extract_text_from_pdf(file):

Â  Â  """

Â  Â  Extracts text content from a PDF file.



Â  Â  Args:

Â  Â  Â  Â  file: A file-like object representing the PDF.



Â  Â  Returns:

Â  Â  Â  Â  A string containing all extracted text from the PDF.

Â  Â  """

Â  Â  text = ""

Â  Â  with pdfplumber.open(file) as pdf:

Â  Â  Â  Â  for page in pdf.pages:

Â  Â  Â  Â  Â  Â  page_text = page.extract_text()

Â  Â  Â  Â  Â  Â  if page_text:

Â  Â  Â  Â  Â  Â  Â  Â  text += page_text + "\n"

Â  Â  return text



# Function to extract text from DOCX

def extract_text_from_docx(file):

Â  Â  """

Â  Â  Extracts text content from a DOCX file.



Â  Â  Args:

Â  Â  Â  Â  file: A file-like object representing the DOCX.



Â  Â  Returns:

Â  Â  Â  Â  A string containing all extracted text from the DOCX.

Â  Â  """

Â  Â  doc = Document(file)

Â  Â  return "\n".join([para.text for para in doc.paragraphs])



# Function to extract details from resume text

def extract_details(text):

Â  Â  """

Â  Â  Extracts key details (Name, Email, Phone, Profile, Experience, Education, Skills, Projects,

Â  Â  Position of Responsibility) from the resume text using a combination of regex and spaCy NLP.



Â  Â  Args:

Â  Â  Â  Â  text: The full text content of the resume.



Â  Â  Returns:

Â  Â  Â  Â  A dictionary containing the extracted details.

Â  Â  """

Â  Â  doc = nlp(text)



Â  Â  # Initialize details dictionary with default "Not found" for all fields

Â  Â  details = {

Â  Â  Â  Â  "Name": "Not found",

Â  Â  Â  Â  "Email": "Not found",

Â  Â  Â  Â  "Phone": "Not found",

Â  Â  Â  Â  "Profile": "Not found",

Â  Â  Â  Â  "Professional Experience": "Not found",

Â  Â  Â  Â  "Education": "Not found",

Â  Â  Â  Â  "Skills": "Not found",

Â  Â  Â  Â  "Projects": "Not found",

Â  Â  Â  Â  "Position of Responsibility": "Not found"

Â  Â  }



Â  Â  # Extract email and phone using regular expressions

Â  Â  email = re.findall(r'[\w\.-]+@[\w\.-]+', text)

Â  Â  phone = re.findall(r'\+?\d[\d\-\s]{8,}\d', text)

Â  Â  if email:

Â  Â  Â  Â  details["Email"] = email[0]

Â  Â  if phone:

Â  Â  Â  Â  details["Phone"] = phone[0]



Â  Â  # Split text into lines and clean them (remove empty lines and strip whitespace)

Â  Â  lines = text.splitlines()

Â  Â  cleaned_lines = [line.strip() for line in lines if line.strip()]



Â  Â  # Attempt to extract name from the first few lines using spaCy's PERSON entity recognition

Â  Â  # and a fallback to the first line if it looks like a name.

Â  Â  name_candidates = []

Â  Â  for i in range(min(5, len(cleaned_lines))): # Check the first 5 lines for potential names

Â  Â  Â  Â  line_doc = nlp(cleaned_lines[i])

Â  Â  Â  Â  for ent in line_doc.ents:

Â  Â  Â  Â  Â  Â  # Look for PERSON entities that are at least two words long (e.g., "K SUDHEERA")

Â  Â  Â  Â  Â  Â  if ent.label_ == "PERSON" and len(ent.text.split()) >= 2:

Â  Â  Â  Â  Â  Â  Â  Â  name_candidates.append(ent.text)

Â  Â  Â  Â  # Also consider the very first line as a strong name candidate if it's short and capitalized

Â  Â  Â  Â  if i == 0 and (cleaned_lines[0].isupper() or cleaned_lines[0].istitle()) and len(cleaned_lines[0].split()) <= 4:

Â  Â  Â  Â  Â  Â  name_candidates.append(cleaned_lines[0])

Â  Â Â 

Â  Â  # Prioritize the first strong name candidate found

Â  Â  if name_candidates:

Â  Â  Â  Â  details["Name"] = name_candidates[0]



Â  Â  # Define common resume section keywords and their corresponding keys in the details dictionary.

Â  Â  # The order here can influence parsing if sections have similar keywords.

Â  Â  section_keywords = {

Â  Â  Â  Â  "PROFILE": "Profile",

Â  Â  Â  Â  "PROFESSIONAL EXPERIENCE": "Professional Experience",

Â  Â  Â  Â  "EDUCATION": "Education",

Â  Â  Â  Â  "SKILLS": "Skills",

Â  Â  Â  Â  "PROJECTS": "Projects",

Â  Â  Â  Â  "POSITION OF RESPONSIBILITY": "Position of Responsibility"

Â  Â  }



Â  Â  # Temporary dictionary to hold lists of lines for each section before joining

Â  Â  current_section_data = {key: [] for key in details if key not in ["Name", "Email", "Phone"]}

Â  Â  current_section_name = None # Tracks the current section being parsed



Â  Â  for line in cleaned_lines:

Â  Â  Â  Â  line_upper = line.upper()

Â  Â  Â  Â  found_new_section = False

Â  Â  Â  Â  # Check if the current line is a new section header

Â  Â  Â  Â  for keyword, section_key in section_keywords.items():

Â  Â  Â  Â  Â  Â  # Match if the keyword is present and the line isn't too long (to avoid false positives)

Â  Â  Â  Â  Â  Â  if keyword in line_upper and len(line_upper) < len(keyword) + 15: # Increased buffer slightly

Â  Â  Â  Â  Â  Â  Â  Â  current_section_name = section_key

Â  Â  Â  Â  Â  Â  Â  Â  found_new_section = True

Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â Â 

Â  Â  Â  Â  # If not a new section header, and we are currently in a section, add the line to it

Â  Â  Â  Â  if not found_new_section and current_section_name:

Â  Â  Â  Â  Â  Â  if current_section_name == "Skills":

Â  Â  Â  Â  Â  Â  Â  Â  # Special handling for skills: split by common delimiters and bullet points

Â  Â  Â  Â  Â  Â  Â  Â  # This regex splits by spaces, unicode bullet (â€¢), comma, and semicolon

Â  Â  Â  Â  Â  Â  Â  Â  skill_items = re.split(r'[\s\u2022,\;]+', line.replace('â€¢', '').strip())

Â  Â  Â  Â  Â  Â  Â  Â  # Filter out any empty strings resulting from the split and add to skills list

Â  Â  Â  Â  Â  Â  Â  Â  current_section_data[current_section_name].extend([s.strip() for s in skill_items if s.strip()])

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  # For other sections, just append the line

Â  Â  Â  Â  Â  Â  Â  Â  current_section_data[current_section_name].append(line)



Â  Â  # Join the lists of lines into single strings for the final output dictionary

Â  Â  for key, value_list in current_section_data.items():

Â  Â  Â  Â  if value_list:

Â  Â  Â  Â  Â  Â  if key == "Skills":

Â  Â  Â  Â  Â  Â  Â  Â  # Ensure unique skills and join them with ", "

Â  Â  Â  Â  Â  Â  Â  Â  details[key] = ", ".join(sorted(list(set(value_list))))

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  # Join other sections with newlines

Â  Â  Â  Â  Â  Â  Â  Â  details[key] = "\n".join(value_list)

Â  Â  Â  Â  # If a section's list is empty, it remains "Not found" as initialized



Â  Â  return details



# ----------------------------

# Streamlit App Starts Here

# ----------------------------



st.set_page_config(page_title="Resume Parser", layout="centered")

st.title("ðŸ“„ Resume Parser")

st.write("Upload a PDF or DOCX resume to extract key information in a simple format.")



# File uploader widget

uploaded_file = st.file_uploader("Choose your resume file", type=["pdf", "docx"])



if uploaded_file is not None:

Â  Â  # Determine file type and extract text accordingly

Â  Â  if uploaded_file.name.endswith(".pdf"):

Â  Â  Â  Â  text = extract_text_from_pdf(uploaded_file)

Â  Â  elif uploaded_file.name.endswith(".docx"):

Â  Â  Â  Â  text = extract_text_from_docx(uploaded_file)

Â  Â  else:

Â  Â  Â  Â  st.error("Unsupported file format. Please upload a .pdf or .docx file.")

Â  Â  Â  Â  st.stop() # Stop execution if file format is not supported



Â  Â  # Process and display extracted details

Â  Â  st.success("âœ… Resume uploaded and processed successfully!")

Â  Â  st.subheader("ðŸ“‹ Extracted Resume Details:")



Â  Â  details = extract_details(text)



Â  Â  # Display the extracted details in a formatted way

Â  Â  for key, value in details.items():

Â  Â  Â  Â  st.markdown(f"**{key}:**") # Always display the key as a header

Â  Â  Â  Â  if key in ["Profile", "Professional Experience", "Education", "Projects", "Position of Responsibility"]:

Â  Â  Â  Â  Â  Â  # For these sections, split by newline and display as bullet points

Â  Â  Â  Â  Â  Â  if value != "Not found":

Â  Â  Â  Â  Â  Â  Â  Â  for line in value.split('\n'):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if line.strip(): # Only display non-empty lines

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"- {line.strip()}")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(value) # Display "Not found" if no content

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  # For Name, Email, Phone, Skills, display directly

Â  Â  Â  Â  Â  Â  st.markdown(value)



Â  Â  st.markdown("---")

Â  Â  st.info("You can upload another resume to re-analyze.")



